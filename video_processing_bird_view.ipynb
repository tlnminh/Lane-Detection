{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "#import skvideo.io\n",
    "def transformImage(image, src, dst):\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (image.shape[1], image.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    return warped\n",
    "\n",
    "def show_image(image):\n",
    "    key = 0;\n",
    "    while (key != 27):\n",
    "        cv2.imshow(\"Image\", image)\n",
    "        key = cv2.waitKey(10)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_path(img, img_eroded, min_y, max_y, direction, center_x_old, tolerance, sum_required, straight_count, straight_flag, count, junction_flag, junction_frame):\n",
    "    global center_x\n",
    "    center_x = 320\n",
    "    ### detect center of lanes\n",
    "    histogram = []\n",
    "    point = []\n",
    "    point_1=[]\n",
    "    point_2=[]\n",
    "    sum_f = []\n",
    "    width=128\n",
    "    text_scale=0.3\n",
    "    color = (255,255,255)\n",
    "    thickness = 1\n",
    "    \n",
    "    histogram = np.zeros((width,), dtype=int)\n",
    "#    img_roi = img_eroded[min_y:max_y, :, 1] #if 3 channels\n",
    "    img_roi = img_eroded[min_y:max_y, :]\n",
    "    histogram = np.apply_along_axis(np.count_nonzero, 0, img_roi)\n",
    "    \n",
    "    for w in range(0, len(histogram)-1):\n",
    "        if (histogram[w]!=0 and histogram[w-1]==0) or (histogram[w]!=0 and histogram[w+1]==0):\n",
    "            point.append(w)\n",
    "            \n",
    "    for no in range(0,len(point)-1):\n",
    "        if np.sum(histogram[point[no]:point[no+1]]) > sum_required :\n",
    "            point_1.append(point[no])\n",
    "            point_2.append(point[no+1])\n",
    "    #print histogram        \n",
    "    ### detect center of path\n",
    "    if len(point_1) == 1:\n",
    "        cv2.putText(img,'1 lane detected',(0,120),cv2.FONT_HERSHEY_SIMPLEX, text_scale,color,thickness,cv2.LINE_AA)\n",
    "        center_lanes = (point_1[0]+point_2[0])/2\n",
    "        if junction_flag == 1:\n",
    "            if direction == \"left\":\n",
    "                if center_lanes<43:\n",
    "                    center_x = (center_lanes+128)/2\n",
    "                else:\n",
    "                    center_x = center_lanes/2\n",
    "            elif direction == \"right\":\n",
    "                if center_lanes>86:\n",
    "                    center_x = center_lanes/2\n",
    "                else:\n",
    "                    center_x = (center_lanes+128)/2\n",
    "        else:\n",
    "            if center_lanes>center_x_old:\n",
    "                center_x = center_lanes/2\n",
    "            elif center_lanes<center_x_old:\n",
    "                center_x = (center_lanes+128)/2\n",
    "            \n",
    "    elif len(point_1) == 2:\n",
    "        cv2.putText(img,'2 lanes detected',(0,120),cv2.FONT_HERSHEY_SIMPLEX, text_scale,color,thickness,cv2.LINE_AA)\n",
    "        center_x=(point_1[0]+point_1[1]+point_2[0]+point_2[1])/4\n",
    "        # straight\n",
    "        if abs(point_1[0]-point_2[0]) < 15 and abs(point_1[1]-point_2[1]) < 15 and junction_flag == 0:\n",
    "            straight_count+=1\n",
    "        if straight_count>100:\n",
    "            straight_flag = 1\n",
    "            \n",
    "    elif len(point_1) == 0:\n",
    "        cv2.putText(img,'nothing is detected',(5,120),cv2.FONT_HERSHEY_SIMPLEX, text_scale,color,thickness,cv2.LINE_AA)\n",
    "        center_x=center_x_old\n",
    "        \n",
    "    if straight_flag == 1:\n",
    "        cv2.putText(img,'straight',(5,30),cv2.FONT_HERSHEY_SIMPLEX, text_scale,color,thickness,cv2.LINE_AA)\n",
    "        cv2.rectangle(img, (center_x_old-15,34), (center_x_old+15,54), color, thickness)\n",
    "\n",
    "        # junction?\n",
    "        img_roi = img_eroded[44:64,center_x_old-15:center_x_old+15]\n",
    "        if np.sum(np.apply_along_axis(np.count_nonzero, 0, img_roi)) > 15 and junction_flag == 0:\n",
    "            cv2.putText(img,'junction',(5,50),cv2.FONT_HERSHEY_SIMPLEX, text_scale,color,thickness,cv2.LINE_AA)\n",
    "\n",
    "            junction_flag = 1\n",
    "            junction_frame = count\n",
    "            straight_flag = 0\n",
    "            straight_count = 0\n",
    "            \n",
    "    if (junction_flag==1 and len(point_1)==1) == False:      \n",
    "        if center_x_old!=0 and abs(center_x-center_x_old)>tolerance:\n",
    "            center_x=center_x_old \n",
    "    \n",
    "    if count > junction_frame + 100:\n",
    "        junction_flag = 0\n",
    "    \n",
    "    if junction_flag == 1:\n",
    "        cv2.putText(img,'junc_flag',(5,70),cv2.FONT_HERSHEY_SIMPLEX, text_scale,color,thickness,cv2.LINE_AA)\n",
    "        \n",
    "        if direction == \"left\":\n",
    "            cv2.putText(img,'turn left',(60,10),cv2.FONT_HERSHEY_SIMPLEX, text_scale,color,thickness,cv2.LINE_AA)\n",
    "        if direction == \"right\":\n",
    "            cv2.putText(img,'turn right',(60,10),cv2.FONT_HERSHEY_SIMPLEX, text_scale,color,thickness,cv2.LINE_AA)\n",
    "            \n",
    "    center_x_old = center_x\n",
    "    \n",
    "    cv2.circle( img, (center_x, (min_y+max_y)/2), 4, color, -1, 8 )\n",
    "    cv2.putText(img,'center',(center_x, (min_y+max_y)/2),cv2.FONT_HERSHEY_SIMPLEX, text_scale,color,thickness,cv2.LINE_AA)\n",
    "    \n",
    "    cv2.line(img, (0, min_y), (129, min_y), color, thickness)\n",
    "    cv2.line(img, (0, max_y), (129, max_y), color, thickness)\n",
    "    \n",
    "    return center_x_old, straight_count, straight_flag, junction_flag, junction_frame\n",
    "#    cv2.imwrite('/home/phamthinh/jupyter/media/fuck.jpg', img_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "low_threshold = 150\n",
    "high_threshold = 255\n",
    "polygon = np.array([ [0,479], [740,479], [740,200] , [0,200] ], np.int32)\n",
    "polygon2 = np.array([[362, 180], [0, 480], [1040, 480], [678, 180]], np.int32)\n",
    "polygon2 = polygon2.reshape((-1,1,2))\n",
    "polygon3 = np.array([[130, 270], [130, 480], [800, 480], [800, 270]])\n",
    "polygon3 = polygon3.reshape((-1,1,2))\n",
    "element = cv2.getStructuringElement(cv2.MORPH_RECT,(2*7+1,2*2+1))\n",
    "element1 = cv2.getStructuringElement(cv2.MORPH_RECT,(2*3+1,2*1+1))\n",
    "kernel = np.ones((2, 2), np.uint8)\n",
    "center_x_old= 0\n",
    "junction_flag = 0 \n",
    "junction_frame = 0\n",
    "# variable for lane_detection\n",
    "direction = \"right\"\n",
    "tolerance = 30\n",
    "min_y=80\n",
    "max_y=100\n",
    "sum_required = 20\n",
    "straight_count = 0\n",
    "straight_flag = 0\n",
    "#variable for thresholding\n",
    "thresh = 220\n",
    "maxValue = 255\n",
    "\n",
    "cap = cv2.VideoCapture('/home/phamthinh/jupyter/media/clips/output13.avi')\n",
    "\n",
    "frame_width = 128\n",
    "frame_height = 128\n",
    "#fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "#out = cv2.VideoWriter('media/output14.avi',cv2.VideoWriter_fourcc(*'40'), 30, (frame_width,frame_height)) \n",
    "\n",
    "IMAGE_H = 450\n",
    "IMAGE_W = 640\n",
    "src = np.float32([[362, 180], [0, 480], [678, 180], [1040, 480]])\n",
    "#dst = np.float32([[200, 100], [200, IMAGE_H+30], [740, 100], [740, IMAGE_H+30]])\n",
    "dst = np.float32([[200, 0], [200, IMAGE_H+30], [840, 0], [840, IMAGE_H+30]])\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        count+=1\n",
    "        frame = cv2.flip(frame,1)\n",
    "        frame = cv2.copyMakeBorder(frame, 0, 0, 200, 200, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "        original_frame = frame;\n",
    "        frame = transformImage(frame,src,dst)\n",
    "        cv2.polylines(original_frame, [polygon2], True, (255,0,255), 10)\n",
    "#        cv2.imshow(\"Original\", original_frame)\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #cv2.polylines(gray, [polygon3], True, (255,0,255), 10)\n",
    "        gray = gray[0:480, 200:840]\n",
    "        gray = cv2.resize(gray, (128, 128), interpolation=cv2.INTER_LINEAR)\n",
    "#        cv2.imshow(\"Transformed\", gray)\n",
    "#        cv2.waitKey(1)\n",
    "        # Set thamehold and maxValue\n",
    "    \n",
    "        #### added from video processing \n",
    "\n",
    "        # Basic threshold example\n",
    "        th, img_thres = cv2.threshold(gray, thresh, maxValue, cv2.THRESH_BINARY);\n",
    "\n",
    "        img_eroded = cv2.erode(img_thres, kernel, iterations=1)\n",
    "\n",
    "        center_x_old, straight_count, straight_flag, junction_flag, junction_frame =center_path(gray, img_eroded,min_y,max_y, direction, center_x_old, tolerance, sum_required, straight_count, straight_flag, count, junction_flag, junction_frame)\n",
    "#        out.write(gray)\n",
    "        #### added from video processing\n",
    "        cv2.imwrite('/home/phamthinh/jupyter/media/bird view frames/fr_g%d.jpg' %count, gray)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "#out.release()\n",
    " \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = cv2.imread('/media/azure/446455ed-0b48-42de-a754-fdd085a8d1791/github/CarND-Advanced-Lane-Lines-master/videos/frames_original/frame1.jpg')\n",
    "test_img = cv2.copyMakeBorder(test_img, 0, 0, 200, 200, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "IMAGE_H = 450\n",
    "#IMAGE_H = 875\n",
    "IMAGE_W = 1040\n",
    "src = np.float32([[362, 180], [0, 480], [678, 180], [1040, 480]])\n",
    "dst = np.float32([[200, 0], [200, IMAGE_H+30], [740, 0], [740, IMAGE_H+30]])\n",
    "#dst = np.float32([[200, 100], [200, IMAGE_H+100], [1240, 100], [1240, IMAGE_H+100]])\n",
    "#test_img = transformImage(test_img,src,dst)\n",
    "#polygon2 = np.array([[10,5],[20,30],[70,20],[50,10]], np.int32)\n",
    "polygon2 = np.array([[362, 180], [0, 480], [1040, 480], [678, 180]], np.int32)\n",
    "polygon2 = polygon2.reshape((-1,1,2))\n",
    "cv2.polylines(test_img, [polygon2], True, (255,0,255), 10)\n",
    "\n",
    "show_image(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0\n"
     ]
    }
   ],
   "source": [
    "file_object = open(\"/media/azure/446455ed-0b48-42de-a754-fdd085a8d1791/Dataset/Behavioral_cloning/data13/data13.txt\", 'r')\n",
    "print(file_object.read(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
